{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Lab — Cloud Training Server (GPU)\n",
    "\n",
    "This notebook runs a PyTorch training server with **free GPU** that connects to Neural Lab.\n",
    "\n",
    "**Instructions:**\n",
    "1. Go to **Runtime → Change runtime type** and select **T4 GPU**\n",
    "2. Run all cells (Ctrl+F9)\n",
    "3. Copy the **ngrok URL** printed at the bottom\n",
    "4. **Open Neural Lab in your browser over HTTP** (not as a file). In the Neural Lab folder run: `python -m http.server 8000` then open http://localhost:8000\n",
    "5. In Neural Lab, enable **Cloud GPU**, paste the ngrok URL, and click **Test**\n",
    "\n",
    "> You need a free ngrok account. Sign up at [ngrok.com](https://ngrok.com), then copy your auth token from the [dashboard](https://dashboard.ngrok.com/get-started/your-authtoken).\n",
    "\n",
    "> If you open Neural Lab by double-clicking index.html (file://), the browser will block requests to ngrok and you'll see \"NetworkError when attempting to fetch resource\". Always use a local server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install dependencies\n",
    "!pip install -q flask pyngrok torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Set your ngrok auth token (get it from https://dashboard.ngrok.com/get-started/your-authtoken)\n",
    "NGROK_AUTH_TOKEN = \"\"  # <-- Paste your token here\n",
    "\n",
    "from pyngrok import ngrok\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Training server\n",
    "import json, torch, time, threading\n",
    "from flask import Flask, request, jsonify, Response, stream_with_context\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.after_request\n",
    "def add_cors(response):\n",
    "    response.headers[\"Access-Control-Allow-Origin\"] = \"*\"\n",
    "    response.headers[\"Access-Control-Allow-Headers\"] = \"Content-Type, ngrok-skip-browser-warning\"\n",
    "    response.headers[\"Access-Control-Allow-Methods\"] = \"GET, POST, OPTIONS\"\n",
    "    return response\n",
    "\n",
    "@app.route(\"/ping\", methods=[\"GET\", \"OPTIONS\"])\n",
    "def ping():\n",
    "    if request.method == \"OPTIONS\":\n",
    "        return \"\", 204\n",
    "    return jsonify({\"status\": \"ok\", \"device\": str(device)})\n",
    "\n",
    "@app.route(\"/train\", methods=[\"POST\", \"OPTIONS\"])\n",
    "def train():\n",
    "    if request.method == \"OPTIONS\":\n",
    "        return \"\", 204\n",
    "\n",
    "    config = request.get_json(force=True)\n",
    "    nodes_cfg = config[\"nodes\"]\n",
    "    conn_list = config[\"connections\"]\n",
    "    data = config[\"trainingData\"]\n",
    "    lr = float(config.get(\"learningRate\", 0.5))\n",
    "    epochs = int(config.get(\"epochs\", 500))\n",
    "    input_labels = config[\"inputLabels\"]\n",
    "    topo_order = config[\"topologicalOrder\"]\n",
    "\n",
    "    if not data:\n",
    "        return jsonify({\"error\": \"No training data provided\"})\n",
    "\n",
    "    incoming = {}\n",
    "    for c in conn_list:\n",
    "        incoming.setdefault(c[\"to\"], []).append(c[\"from\"])\n",
    "\n",
    "    params = {}\n",
    "    param_list = []\n",
    "    for nid, node in nodes_cfg.items():\n",
    "        if node[\"type\"] in (\"weight\", \"bias\"):\n",
    "            p = torch.tensor(float(node[\"value\"]), dtype=torch.float32, device=device, requires_grad=True)\n",
    "            params[nid] = p\n",
    "            param_list.append(p)\n",
    "\n",
    "    if not param_list:\n",
    "        return jsonify({\"error\": \"No trainable parameters (weights/biases) found\"})\n",
    "\n",
    "    optimizer = torch.optim.SGD(param_list, lr=lr)\n",
    "    loss_history = []\n",
    "    report_interval = max(1, epochs // 200)\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "        for row in data:\n",
    "            tensors = {}\n",
    "            for nid in topo_order:\n",
    "                node = nodes_cfg.get(nid)\n",
    "                if not node:\n",
    "                    continue\n",
    "                ntype = node[\"type\"]\n",
    "                inc = incoming.get(nid, [])\n",
    "\n",
    "                if ntype == \"input\":\n",
    "                    idx = input_labels.index(node[\"label\"]) if node[\"label\"] in input_labels else 0\n",
    "                    val = float(row[\"inputs\"][idx]) if idx < len(row[\"inputs\"]) else 0.0\n",
    "                    tensors[nid] = torch.tensor(val, dtype=torch.float32, device=device)\n",
    "                elif ntype == \"bias\":\n",
    "                    tensors[nid] = params[nid]\n",
    "                elif ntype == \"weight\":\n",
    "                    if not inc:\n",
    "                        tensors[nid] = params[nid]\n",
    "                    else:\n",
    "                        s = torch.tensor(0.0, device=device)\n",
    "                        for fid in inc:\n",
    "                            t = tensors.get(fid)\n",
    "                            if t is not None:\n",
    "                                s = s + t\n",
    "                        tensors[nid] = s * params[nid]\n",
    "                elif ntype in (\"neuron\", \"activation\"):\n",
    "                    s = torch.tensor(0.0, device=device)\n",
    "                    for fid in inc:\n",
    "                        t = tensors.get(fid)\n",
    "                        if t is not None:\n",
    "                            s = s + t\n",
    "                    act = node.get(\"activation\", \"linear\")\n",
    "                    if act == \"sigmoid\":\n",
    "                        s = torch.sigmoid(s)\n",
    "                    elif act == \"relu\":\n",
    "                        s = torch.relu(s)\n",
    "                    elif act == \"tanh\":\n",
    "                        s = torch.tanh(s)\n",
    "                    tensors[nid] = s\n",
    "                elif ntype == \"output\":\n",
    "                    s = torch.tensor(0.0, device=device)\n",
    "                    for fid in inc:\n",
    "                        t = tensors.get(fid)\n",
    "                        if t is not None:\n",
    "                            s = s + t\n",
    "                    tensors[nid] = s\n",
    "\n",
    "            predicted = tensors.get(\"output\", torch.tensor(0.0, device=device))\n",
    "            diff = predicted - float(row[\"expected\"])\n",
    "            total_loss = total_loss + diff ** 2\n",
    "\n",
    "        loss = total_loss / len(data)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % report_interval == 0 or epoch == epochs - 1:\n",
    "            loss_history.append(round(loss.item(), 8))\n",
    "\n",
    "    elapsed = round(time.time() - t0, 3)\n",
    "\n",
    "    trained_weights = []\n",
    "    for nid, p in params.items():\n",
    "        trained_weights.append({\"id\": nid, \"value\": round(p.item(), 6)})\n",
    "\n",
    "    return jsonify({\n",
    "        \"trainedWeights\": trained_weights,\n",
    "        \"lossHistory\": loss_history,\n",
    "        \"finalLoss\": loss_history[-1] if loss_history else 0,\n",
    "        \"epochs\": epochs,\n",
    "        \"elapsed\": elapsed,\n",
    "        \"device\": str(device),\n",
    "    })\n",
    "\n",
    "@app.route(\"/train_stream\", methods=[\"POST\", \"OPTIONS\"])\n",
    "def train_stream():\n",
    "    if request.method == \"OPTIONS\":\n",
    "        return \"\", 204\n",
    "    config = request.get_json(force=True)\n",
    "    nodes_cfg = config[\"nodes\"]\n",
    "    conn_list = config[\"connections\"]\n",
    "    data = config[\"trainingData\"]\n",
    "    lr = float(config.get(\"learningRate\", 0.5))\n",
    "    epochs = int(config.get(\"epochs\", 500))\n",
    "    input_labels = config[\"inputLabels\"]\n",
    "    topo_order = config[\"topologicalOrder\"]\n",
    "    if not data:\n",
    "        return jsonify({\"error\": \"No training data provided\"})\n",
    "    incoming = {}\n",
    "    for c in conn_list:\n",
    "        incoming.setdefault(c[\"to\"], []).append(c[\"from\"])\n",
    "    params = {}\n",
    "    param_list = []\n",
    "    for nid, node in nodes_cfg.items():\n",
    "        if node[\"type\"] in (\"weight\", \"bias\"):\n",
    "            p = torch.tensor(float(node[\"value\"]), dtype=torch.float32, device=device, requires_grad=True)\n",
    "            params[nid] = p\n",
    "            param_list.append(p)\n",
    "    if not param_list:\n",
    "        return jsonify({\"error\": \"No trainable parameters found\"})\n",
    "    def generate():\n",
    "        t0 = time.time()\n",
    "        optimizer = torch.optim.SGD(param_list, lr=lr)\n",
    "        loss_history = []\n",
    "        report_interval = max(1, epochs // 200)\n",
    "        progress_interval = max(1, epochs // 50)\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = torch.tensor(0.0, device=device)\n",
    "            for row in data:\n",
    "                tensors = {}\n",
    "                for nid in topo_order:\n",
    "                    node = nodes_cfg.get(nid)\n",
    "                    if not node: continue\n",
    "                    ntype, inc = node[\"type\"], incoming.get(nid, [])\n",
    "                    if ntype == \"input\":\n",
    "                        idx = input_labels.index(node[\"label\"]) if node[\"label\"] in input_labels else 0\n",
    "                        val = float(row[\"inputs\"][idx]) if idx < len(row[\"inputs\"]) else 0.0\n",
    "                        tensors[nid] = torch.tensor(val, dtype=torch.float32, device=device)\n",
    "                    elif ntype == \"bias\": tensors[nid] = params[nid]\n",
    "                    elif ntype == \"weight\":\n",
    "                        if not inc: tensors[nid] = params[nid]\n",
    "                        else:\n",
    "                            s = torch.tensor(0.0, device=device)\n",
    "                            for fid in inc:\n",
    "                                t = tensors.get(fid)\n",
    "                                if t is not None: s = s + t\n",
    "                            tensors[nid] = s * params[nid]\n",
    "                    elif ntype in (\"neuron\", \"activation\"):\n",
    "                        s = torch.tensor(0.0, device=device)\n",
    "                        for fid in inc:\n",
    "                            t = tensors.get(fid)\n",
    "                            if t is not None: s = s + t\n",
    "                        act = node.get(\"activation\", \"linear\")\n",
    "                        if act == \"sigmoid\": s = torch.sigmoid(s)\n",
    "                        elif act == \"relu\": s = torch.relu(s)\n",
    "                        elif act == \"tanh\": s = torch.tanh(s)\n",
    "                        tensors[nid] = s\n",
    "                    elif ntype == \"output\":\n",
    "                        s = torch.tensor(0.0, device=device)\n",
    "                        for fid in inc:\n",
    "                            t = tensors.get(fid)\n",
    "                            if t is not None: s = s + t\n",
    "                        tensors[nid] = s\n",
    "                predicted = tensors.get(\"output\", torch.tensor(0.0, device=device))\n",
    "                diff = predicted - float(row[\"expected\"])\n",
    "                total_loss = total_loss + diff ** 2\n",
    "            loss = total_loss / len(data)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % report_interval == 0 or epoch == epochs - 1:\n",
    "                loss_history.append(round(loss.item(), 8))\n",
    "            if epoch % progress_interval == 0 or epoch == epochs - 1:\n",
    "                yield f\"event: progress\\ndata: {json.dumps({'loss': round(loss.item(), 6), 'lossHistory': loss_history})}\\n\\n\"\n",
    "        elapsed = round(time.time() - t0, 3)\n",
    "        trained_weights = [{\"id\": nid, \"value\": round(p.item(), 6)} for nid, p in params.items()]\n",
    "        final = {\"trainedWeights\": trained_weights, \"lossHistory\": loss_history, \"finalLoss\": loss_history[-1] if loss_history else 0, \"epochs\": epochs, \"elapsed\": elapsed, \"device\": str(device)}\n",
    "        yield f\"event: complete\\ndata: {json.dumps(final)}\\n\\n\"\n",
    "    return Response(stream_with_context(generate()), content_type=\"text/event-stream\", headers={\"Cache-Control\": \"no-cache\", \"X-Accel-Buffering\": \"no\"})\n",
    "\n",
    "# Start Flask first so it is listening before ngrok connects\n",
    "def run_server():\n",
    "    app.run(host=\"0.0.0.0\", port=5000, use_reloader=False)\n",
    "\n",
    "threading.Thread(target=run_server, daemon=True).start()\n",
    "time.sleep(2)  # let Flask bind to port 5000\n",
    "\n",
    "# Get the actual URL string (pyngrok returns a tunnel object, not a string)\n",
    "tunnel = ngrok.connect(5000)\n",
    "public_url = getattr(tunnel, \"public_url\", str(tunnel))\n",
    "if not public_url.startswith(\"http\"):\n",
    "    public_url = \"https://\" + public_url\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"  Neural Lab Cloud Server is running!\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"\")\n",
    "print(f\"  Copy the URL below into Neural Lab (Cloud GPU field):\")\n",
    "print(f\"  {public_url}\")\n",
    "print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Test the tunnel from Colab (run this to verify the URL works)\n",
    "import urllib.request\n",
    "try:\n",
    "    req = urllib.request.Request(public_url + \"/ping\", headers={\"ngrok-skip-browser-warning\": \"1\"})\n",
    "    with urllib.request.urlopen(req, timeout=10) as r:\n",
    "        body = r.read().decode()\n",
    "    print(\"Tunnel OK:\", body)\n",
    "except Exception as e:\n",
    "    print(\"Tunnel test failed:\", e)\n",
    "    print(\"Check that the URL above is correct and try opening it in your browser.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
